---
title: "Gusto Candidates Ranked"
description: "This cohort needs:"
---

### **Who fits the JD best?**

  

This cohort needs:

• People who can **find, reproduce, and document edge cases**

• Students who have **actually tested software**, not just built things

• People who thrive in **fast iteration**, ambiguity, and real-build debugging

• High signal on: clarity, reliability, detail-orientation, and genuine student-workflow empathy

  

After reviewing all applicants, **these are the strongest fits** — the ones who already _do_ the work Labs requires, not just say they want to.

---

## **⭐** 

## **Top Tier — “They’d be productive on week one”**

  

These candidates directly match the work: structured testing, reproducibility, debugging, risk-based thinking, and student workflows.

  

### **1. Afsheen Mohammad**

  

Actual QA/test-engineering background:

• Automated game-outcome testing (Python, hardware interaction)

• Nokia Bell Labs automation + edge-case isolation

• Writes clean repros, collaborates with engineers, understands risk

This is Labs-DNA.

  

### **2. Hanna Berhane**

  

She has lived the pain you’re solving — and worked at scale:

• Supervises IT systems for 20,000+ students

• Built ML early-warning system for ticket delays

• Catches cascading workflow failures before they explode

She understands the difference between “confusing UI” and “this will break Add/Drop Week.”

  

### **3. Dongyoung (Ryan) Kang**

  

Strong product-testing muscle:

• Microsoft → workflow mapping + product gap identification

• QA for medical apps with large datasets

• Deep experience with reproducibility, user-observed failures, and rapid fixes

Technically sharp, product-aware.

  

### **4. Arshnoor Bhutani**

  

High-signal engineering + rapid-iteration thinker:

• Full-stack + ML + React + testing background

• Validated workflows with real users

• Clear writing, structured bug documentation, student perspective

She’d be extremely effective.

  

### **5. Mira Saini**

  

Already does DormWay-like work:

• Leads AI testing pipelines for campus-wide tools

• Debugs failure modes, reduces hallucinations, tunes retrieval logic

• Builds student-facing tools and tests them

She’d slot right in.

  

### **6. Shreyas Jena**

  

From a 2-person founding team → perfect analog:

• Runs PRDs, user research, testing cycles

• Lives in “find the weird break and fix it quietly” land

• Great clarity of communication

Very Labs-ready.

---

## **⭐** 

## **Strong Tier — “Good fits who will contribute quickly”**

  

### **7. Aaron Huang**

  

Fantastic operational instincts, pattern-recognition, systemization.

Not technical QA, but sees friction early and fixes workflows.

  

### **8. Abdisamad Abdulkadir**

  

Business/tech hybrid with real bug-triage experience at Veeam.

Understands product constraints + reproducibility.

  

### **9. Ariel Shehter**

  

Sharp CS student; competitive programming background means

he’s strong at debugging, systems thinking, and logical isolation.

  

### **10. Sergiy Maltsev**

  

Methodical software-engineering mindset; thoughtful about edge cases;

comfortable breaking things and documenting them.

  

### **11. Tammie Chen**

  

UX + testing + student tooling experience, clear communicator,

comfortable with ambiguity.

  

### **12. Troy Corbitt**

  

Excellent at structured user research + issue identification;

very thoughtful about how people actually use tools.

---

## **⭐ “Interview if room allows”**

  

Good candidates, less tightly aligned with QA-heavy core of Labs:

  

• Catalina Giang

• Arlaghn Cayanan

• Claire Cao

• Kamar Alsamerraey

• Fatima Algahaim

• Izma Arshad

• Yimin Huang

• Toluwani Oyeleke

• Richard Luo

• Smit Bhatt

(all solid product thinkers; weaker direct testing signal)
